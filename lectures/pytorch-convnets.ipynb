{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvoluční sítě v PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pozn.:** Modul `ans.py` se musí nacházet buď ve stejném adresáři, ze kterého je spuštěný tento notebook, nebo v aresáři, jehož cesta je zapsaná v vystémové proměnné PYTHONPATH.\n",
    "\n",
    "Před supštěním příkazu `jupyter notebook` tedy nastavte:\n",
    "- na Windows: `set PYTHONPATH=c:\\path\\to\\ans-repo;%PYTHONPATH%`\n",
    "- na Linuxu: `export PYTHONPATH=/path/to/ans-repo:$PYTHONPATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvoluce v PyTorch pomocí vrstvy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V PyTorch jsou vrstvy různých typů definované v modulu `nn`. Např. konvoluční vrstva je definována jako třída `Conv2d` obalující funkci `torch.nn.functional.conv2d`, přičemž si uchovává parametry `weight`, `bias` a další. V implementaci dopředného průchodu vrstvy `nn.Conv2d` najdeme:\n",
    "\n",
    "``` python\n",
    "class Conv2d(_ConvNd):\n",
    "    r\"\"\"Applies a 2D convolution over an input signal composed of several input\n",
    "    planes.    \n",
    "    ...\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        # ... inicializace a dalsi\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.weight, self.bias, self.stride, \n",
    "            self.padding, self.dilation, self.groups\n",
    "```\n",
    "\n",
    "Podobně jsou definovány i ostatní vrstvy, jako např. lineární atd. Rozdílem oproti manuální implementaci z minulých cvičení je absence definice zpětného průchodu. Ten je definován na nižší úrovni kódu v C++ v knihovně ATen, na níž PyTorch staví. O jeho zavolání ve správný čas ve zpětné propoagaci se postará PyTorch modul autograd. Např. jiná knihovna [Chainer](https://chainer.org/) je naopak stavěná tak, že zpětný průchod je definován explicitně přímo v Pythonu u každé operace, a to jak pro CPU, tak pro GPU (CUDA). Jde tedy o podobný způsob jako u cvičení [multilayer-perceptron](multilayer-perceptron.ipynb). Výhodou může být, že u každé vrstvy lze krokováním projít výpočet gradientů na jednotlivé parametry a vstupy.\n",
    "\n",
    "Konvoluční vrstvu v PyTorch vytvoříme jako objekt typu `nn.Conv2d`, jehož kontruktor po nás chce počet výstupních kanálů konvoluce (=počet filtrů), počet vstupních kanálů (=3 pro RGB), velikost filtru (=3 pro filtr 3x3), a zda chceme přičítat i bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, 3, padding=1, bias=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch všechny vrstvy při vytvoření defaultně inicializuje. Vlastní nastavení je možné, např.\n",
    "``` python\n",
    "nn.init.xavier_uniform(conv.weight)\n",
    "```\n",
    "nebo přímo kopírováním do `conv.weight` metodou `copy_`.\n",
    "\n",
    "Před aplikací vrstvy nejprve načteme obrázek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_test = imread('../data/happy-green-frog.jpg')\n",
    "\n",
    "plt.imshow(rgb_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Všechny vrstvy očekávají 4D vstup ve formátu *dávka x kanály x výška x šířka* a defaultně jako typ `float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = rgb_test.transpose(2, 0, 1)  # prevod na kanaly x vyska x sirka\n",
    "input_tensor = input_tensor[None]  # navic dimenze davky\n",
    "input_tensor = torch.from_numpy(input_tensor / 255.).float() # prevod do PyTorch a float32 v rozsahu 0..1\n",
    "input_tensor.dtype, input_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopředný průchod už je jednoduchý:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = conv(input_tensor)\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak jsme si ukazovali na přednášce, konvoluce v neurosítích se obvykle používá ve spojení s max poolingem, který na na každém typicky např. 2x2 okně počítá maximum. Na rozdíl od konvoluce se okénka typicky nepřekrývají a výstup je tedy menší než vstup, např. poloviční pro 2x2 max pool okénko.\n",
    "\n",
    "V PyTorchi je max pooling implementován třídou `torch.nn.MaxPool2d`, která obaluje funkci `torch.nn.functional.max_pool2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_size = 2, stride = None --> 2x2 okenko s krokem 2\n",
    "pool = nn.MaxPool2d(2)\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_output = pool(conv_output)\n",
    "pool_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definice konvoluční sítě"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocí `torch.nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch umožňuje více způsobů definice vlastní neuronové sítě. Nejjednodušším je pomocí třídy `torch.nn.Sequential`, do níž zadáme seznam vrstev, jak jdou za sebou. Tím je zároveň definován dopředný průchod, který proto nemusíme ručně implementovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = nn.Sequential(\n",
    "    nn.Conv2d(3, 1, 3, padding=1, bias=False),\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následující kód provede dopředný průchod konvolucí a poté max-pooling stejně, jako jsme to udělali nahoře."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_output = seq(input_tensor)\n",
    "seq_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocí třídy odvozené z `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Třída `Sequential` je však poměrně limitovaná. Vývojáři PyTorch záměrně [odmítají](https://github.com/pytorch/pytorch/issues/2118#issuecomment-315625012) implementovat některé operace jako vrstvy proto, aby tím nemotivovali uživatele používat tuto jednoduchou třídu. Není tak dostupná např. operace `view`/`reshape`, jež je potřeba pro propojení konvoluční mapy a následné lineární vrstvy. Třída `torch.nn.Linear` totiž vyžaduje, aby vstup byl formátu *dávka x vektor*, zatímco konv. mapy mají dimenze *dávka x kanály x výška x šířka*.\n",
    "\n",
    "Druhým, oficiálním a doporučeným postupem je definice vlastní třídy odvozené od `torch.nn.Module`. Tento způsob je sice poněkud \"ukecanější\", ale zato mnohem flexibilnější. Stejný model jako pomocí třídy `Sequential` zadefinujeme následovně."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(3, 1, 3, padding=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv()\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = conv(input_tensor)\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kombinovaná síť"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvoříme rovněž kombinovanou konvoluční síť pro klasifikaci. Po konvolučních vrstvách bude následovat plně propojená vrstva produkující skóre pro jednotlivé třídy tak, jak to známe z minýlch úloh. Všimněme si, že lineární vrstva potřebuje znát přesnou velikost výstupu předchozí vrstvy. Jelikož budeme pracovat s obrázky 32x32 a dvakrát zmenšíme na polovinu max-poolingem, poslední konv. mapa bude mít rozměr 8x8.\n",
    "\n",
    "**Pozn.:** jelikož vrstvy jako např. max pooling či ReLU nemají žádné trénovatelné parametry, často se jako objekty typu `nn.Module` neinstancují a pouze se aplikují jako funkce v dopředném průchodu. Viz konstruktor a metodu `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # prvni konv. vrstva\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # druha konv. vrstva\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet = Convnet()\n",
    "cnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chceme použít GPU, zavoláme z objektu typu `nn.Module` metodu `to`, která za parametr přijímá datový typ nebo zařízení, do kterého se má model převést. Funkce funguje \"in-place\", tzn. že modifikuje daný objekt, byť na něj zároveň vrací referenci. Následující buňka proto bude mít výstup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametry sítě"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modely v PyTorch umožňují procházet seznam svých parametrů metodami `parameters()` nebo `named_parameters()`. To je důležité např. pro ukládání naučených sítí. Funkce si přitom rekurzivně poradí i s vnořenými modely. To znamená, že výsledný seznam získaný metodou `net.named_parameters()` našeho modelu `Net` obsahuje parametry všech jeho atributů, které jsou typu odvozeného z `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, par in cnet.named_parameters():\n",
    "    print(name, par.shape, par.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatický zpětný průchod v Pytorch: autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knihovna Pytorch umožňuje automatickou derivaci (autograd) a zpětnou propagaci gradientu následujícím způsobem. Pokud vytvoříme jakýkoliv `Tensor` s dodatečným parametrem `requires_grad=True`, knihovna si zapamatuje všechny operace s ním provedené. Viz příklad přímo z [pytorch.org](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud s `x` něco provedeme, autograd si to zapamatuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Další dvě operace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = z.mean()\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch autograd si nyní pamatuje celou historii výpočtů od `x` až po `w`. Na sled výpočtů můžeme nahlížet jako na výpočetní graf, v němž uzly představují jednotlivé proměnné a matematickou funkci, pomocí které jejich hodnota byla vypočtena. Pokud nyní na `w` zavoláme metodu `backward(dout)` s nějakým \"příchozím\" gradientem `dout` (defaultně je `None`), spustí se kompletní zpětná propagace celým výpočetním stromem až k \"listu\" `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zpětný průchod v PyTorch má tedy jiné API než to, co jsme vytvořili v úloze [multilayer-perceptron](multilayer-perceptron.ipynb). Metoda `backward` zde nevrací gradienty na parametry dané vrstvy, ale spustí plnou zpětnou propagaci z její pozice ve výpočetním grafu až ke vstupu. Vypočtené gradienty se přitom úkládají přímo do uzlů tvořených jednotlivými proměnnými, do jejich atributu `grad`.\n",
    "\n",
    "Např. derivace `w` podle `x`, tj. gradient $dw / dx$ je:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovšem pokud bychom se chtěli podívat na $dw / dz$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`z.grad` je `None`, protože PyTorch z důvodů šetření paměti zahazuje mezivýpočty, tj. všechny gradienty, které netvoří list stromu. Pokud bychom ho přesto chtěli vidět, lze na `z` zavolat funkci `retain_grad()` a znovu spustit zpětný průchod. K tomu však musíme znovu vytvořit celý výpočetní graf, jelikož PyTorch po zavolání backpropu defaultně vyčistí jeho buffery (toto chování lze změnit argumentem `retain_graph` metody `backward`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "z = y * y * 3\n",
    "z.retain_grad()\n",
    "w = z.mean()\n",
    "w.backward()\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podívejme se znovu na gradient na `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ačkoliv jsme provedli stejné výpočty, gradient na `x` se změnil! Stalo se tak proto, že autograd ve skutečnosti atribut `grad` nepřepisuje, ale při každém backpropu akumuluje. Tensor `x` totiž nebyl znovu vytvořen, nýbrž byl použit dvakrát a výsledný gradient je proto součtem příchozích gradientů ze dvou pod-stromů.\n",
    "\n",
    "Pokud bychom vytvořili i `x` znovu, reference na původní `x` by přestala existovat, z prvního výpočetního grafu by nezbylo již nic a gradient by byl stejný jako při prvním průchodu. Dokud však proměnná s \"cachovaným\" `grad` existuje, není možné vyčistit paměť, což může být v PyTorch zdrojem nepříjemných bugů a zaplňování paměti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kritérium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zda budeme optimalizovat křížovou entropii (Softmax) nebo hinge loss (SVM) zvolíme vytvořením odpovídajícího objektu. V PyTorch jsou nejčastěji používaná kritéria reprezentovaná jako vrstvy typu `nn.Module` s dopředným průchodem definovaným metodou `forward`, jehož výstup je typicky jediné číslo repezentující hodnotu lossu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()\n",
    "crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda optimalizace parametrů"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch umožňuje trénování pomocí celé řady variant Stochastic Gradient Descentu jako např. momentum SGD, RMSprop, Adam a další. Optimalizátor je objekt, který převezme seznam parametrů, jež má optimalizovat, a výchozí learning rate. Objektu předáme parametry naší `Convnet` a nastavíme learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(cnet.parameters(), lr=0.01)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stěžejní funkcionalitou `optimizer`u je metoda `step`, která updatuje všechny tensory zadané v seznamu parametrů v konstruktoru. Tuto funkci voláme po výpočtu gradientů zpětným průchodem v každé minidávce. V případě `SGD` bez momentu se provede `param -= learning_rate * dparam`, jak to známe z minulých úloh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práce s daty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch unsadňuje práci s daty pomocí předdefinovaných datasetů a loaderů, které umožňují procházení po dávkách. V našem případě pracujeme s CIFAR-10, pro který existuje třída `torchvision.datasets.CIFAR10`, kterou již známe z minulých úloh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro snadnější přípravu dat a případnou agumentaci obsahuje balík torchvision modul `transforms`. Základní třídou obalující funkcionalitu řetezce transformací je `Compose`. Při konstrukci přebírá `list` transformací, které budeme na obrázky aplikovat, např. normalizace na definovanou velikost, odečtení průmeru apod. Jelikož všechny obrázky v CIFAR-10 jsou stejně velké, použijeme zde pouze třídu `ToTensor`, která převede obrázek ze třídy `PIL.Image` na `torch.Tensor` a zároveň s tím normalizuje do rozsahu 0..1 a přeskupí dimenze do formátu *kanály x výška x šířka* tak, jak to konvoluce v PyTorch vyžaduje.\n",
    "\n",
    "*Pozn.:* Transformace `ToTensor` je nutná pro zpracování po dávkách. Pokud bychom ji nepoužili, PyTorch by nevěděl, jak má objekty typu `PIL.Image` seskupit do jedné dávky, tj. souvislého 4D tensoru. Ostatní transformace však pracují právě s `PIL.Image`, proto jí vždy umístíme až na konec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvořený objekt předáme do konstruktoru datasetu jako jeden z parametrů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procházení dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načítání dat po dávkách zajišťuje třída `torch.utils.data.DataLoader`. Do konstruktoru jí předáme objekt datasetu, požadovanou velikost dávky a příp. informaci, zda se mají obrázky vybírat náhodně či postupně za sebou tak, jak jsou seřazeny v datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přes výsledný objekt je možné iterovat a v každém kroku vrátí dvojici `X, y` obrázků a jejich labelů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(train_loader))\n",
    "X_batch.dtype, X_batch.shape, y_batch.dtype, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud používáme GPU, defaultně jsou data na procesoru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(cnet.parameters()).device == X_batch.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stejně jako s modelem, převod na GPU zajistíme zavoláním metody `to('cuda')`. Rozdílem ovšem je, že operace není \"in-place\" a nemodifikuje tak původní data, nýbrž vytváří nové."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(cnet.parameters()).device == X_batch.to('cuda').device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénovací cyklus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní jsou všechny komponenty potřebné pro trénování připravné, stačí tedy sestavit je za sebe do trénovacího cyklu. Ten bude velmi podobný jako v minulých úlohách a je implementován v modulu `ans` metodou `train_pytorch`. Opět se jedná o standardní cyklus, kde se opakuje dopředný průchod, výpočet lossu, zpětný průchod a update parametrů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet_stats = ans.Stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for ep in range(20):\n",
    "    cnet_stats.new_epoch()\n",
    "    ans.train_pytorch(cnet, crit, train_loader, optimizer, cnet_stats)\n",
    "    ans.validate_pytorch(cnet, crit, test_loader, cnet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet_stats.plot_by_batch(block_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet_stats.plot_by_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet_stats.best_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natrénovanou síť můžeme otestovat na obrázku `happy-green-frog`. Problémem ovšem je, že má jiné rozměry než data v CIFARu a musíme ho tak normalizovat na rozlišení 32x32, k čemuž použijeme knihovnu OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.predict_and_show(cv2.resize(rgb_test, (32, 32)), cnet, transform, classes=classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
